---
title: Effects of COVID-19 in Mexico City: street robbery and vehicle theft spatio-temporal patterns
author: "Ana J. Alegre (jalegre@centrogeo.edu.mx), Cristian Silva (csilva@centrogeo.edu.mx)"
date: "8/28/2021"
output: html_document
---

## Introduction

This interactive notebook written in RMarkdown format contains the data processing operations and algorithm mentioned in the *Effects of COVID-19 in Mexico City: street robbery and vehicle theft spatio-temporal patterns* article.

## Data processing

Setup RMarkdown options:
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Increase the memory maximum size for R:
```{r Increase R memory}
options(future.globals.maxSize= 891289600) # Increase memory limit to 850MB = 850*1024^2 = 891289600
```

Load the required packages:
```{r Load required packages}
# It may be required to install previously these packages before loading:
library(tidyverse)
library(lubridate)
library(sf)
library(janitor)
library(mice)
library(units)
library(classInt)
library(tmap)
library(NearRepeat)
```

Read the CDMX's crime incidence data:
```{r Read crime data}
crimes <-
  read_csv("Data/carpetas_completa_junio_2021.csv.zip",
           col_types = "--T--Tccccccccccnnc") %>%  # Specify data types and skip unused columns
  clean_names() %>% # Clean column names
  glimpse()
```

Get a crime catalog from the crime data:
```{r Crime catalog}
# Filter crime data to get unique crime categories :
crime_catalog <-
  crimes %>% 
  distinct(delito, categoria_delito) %>% 
  arrange(delito)

# Filter robbery and save the catalog in a file:
robbery_catalog <-
  crime_catalog %>% 
  filter(str_detect(delito, "(ROBO).*(CON VIOLENCIA)")) %>% 
  write_csv("Data/robbery_catalog_cv.csv")

# Visualize the robbery catalog:
robbery_catalog
```

To define the study period, we will take one year before and one year after the date when pandemics lockdown began on May 16, 2020.
```{r Set study period dates}
lockdown_date <- make_date(2020, 3, 16)
date_start <- lockdown_date - period(1, "year")
date_end <- lockdown_date + period(1, "year")
```

Filter high impact robberies data for the period of study, adding an unique identificator column:
```{r Filter high impact robberies}
# Read english translation for robbery categories:
robberies_translate <- read_csv("Data/robberies_translate.csv")

# Filter high impact robberies and combine with english translation:
hi_robberies <-
  crimes %>% 
  filter(between(date(fecha_hechos), date_start, date_end),
         str_detect(categoria_delito, "ROBO")) %>% 
  left_join(robberies_translate, by = c("categoria_delito" = "original")) %>% 
  mutate(mes_hechos = as_date(cut(fecha_hechos, breaks = "1 month"))) %>% 
  rowid_to_column("id") %>% 
  glimpse()
```

## High impact robberies exploratory data analysis

Visualize high impact robberies monthly trending: 
```{r Monthly trending}
# Create line plot:
hi_robberies %>% 
  group_by(mes_hechos) %>% 
  count(name = "total") %>% 
  ungroup() %>% 
  ggplot(aes(x = mes_hechos, y = total)) +
  geom_line() +
  geom_smooth() +
  labs(title = "High impact theft trending",
       subtitle = "Monthly, December 2017 - June 2021",
       x = "Month",
       y = "Thefts")
```

Identify which high impact robberies had the highest incidence before lockdown:
```{r Robberies before lockdown stats}
robberies_rank_before <-
  hi_robberies %>% 
  filter(date(fecha_hechos) < lockdown_date) %>% 
  group_by(mes_hechos, traducido) %>% 
  count(name = "total_mes", na.rm = T) %>%
  ungroup() %>% 
  group_by(traducido) %>%
  summarize(total = sum(total_mes, na.rm = T),
            promedio = mean(total_mes, na.rm = T),
            minimo = min(total_mes, na.rm = T),
            maximo = max(total_mes, na.rm = T),
            desv_est = sd(total_mes, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(ranking = dense_rank(desc(total)),
         porcentaje = total / sum(total, na.rm = T)) %>% 
  arrange(desc(total)) %>% 
  write_excel_csv("Output/robberies_before_stats.csv")

robberies_rank_before
```

Identify which high impact robberies had the highest incidence after lockdown:
```{r Robberies after lockdown stats}
robberies_rank_after <-
  hi_robberies %>% 
  filter(date(fecha_hechos) >= lockdown_date) %>% 
  group_by(mes_hechos, traducido) %>% 
  count(name = "total_mes", na.rm = T) %>%
  ungroup() %>% 
  group_by(traducido) %>%
  summarize(total = sum(total_mes, na.rm = T),
            promedio = mean(total_mes, na.rm = T),
            minimo = min(total_mes, na.rm = T),
            maximo = max(total_mes, na.rm = T),
            desv_est = sd(total_mes, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(ranking = dense_rank(desc(total)),
         porcentaje = total / sum(total, na.rm = T)) %>% 
  arrange(desc(total)) %>% 
  write_excel_csv("Output/robberies_after_stats.csv")

robberies_rank_after
```

According the results below, street robbery and car theft both accumulate **70% of high impact crimes**. Create a line plot to analyze the trending for each high impact robbery category:
```{r Trending per robbery category}
hi_robberies %>% 
  group_by(mes_hechos, traducido) %>% 
  count(name = "total") %>% 
  ungroup() %>% 
  complete(mes_hechos, nesting(traducido), fill = list(total = 0)) %>% 
  ggplot(aes(x = mes_hechos, y = total, group = traducido)) +
  geom_line() +
  geom_smooth() +
  geom_vline(xintercept = make_date(2020, 3, 16),
             color = "red",
             lty = "dotted") + 
  labs(title = "High-impact robberies trending by type",
       subtitle = "Monthly, March 16th 2019 - March 16th 2020",
       x = "Month",
       y = "Robberies") +
  theme_bw() +
  facet_wrap(~traducido,
             scales = "free_y",
             ncol = 5)
```

Convert data to spatial object and add a date variable without column: 
```{r Convert to spatial}
hi_robberies_points <- 
  hi_robberies %>% 
  st_as_sf(coords = c("longitud", "latitud"), na.fail = F) %>% 
  st_set_crs(4326) %>% 
  mutate(fecha = date(fecha_hechos)) %>% 
  rowid_to_column("id_point") %>% 
  glimpse()
```

## Mobility data analysis

### Apple mobility data

Read and filter Apple's mobility data for Mexico City:
```{r Read Apple mobility data}
mobility_apple <- 
  read_csv("Data/applemobilitytrends-2021-08-24.csv.zip") %>% 
  pivot_longer(cols = (7:596),
               names_to = "date",
               values_to = "mobility") %>% 
  clean_names() %>% 
  mutate(date = dmy(date)) %>% 
  filter(country == "Mexico",
         alternative_name == "Ciudad de México") %>% 
  glimpse()
```

Identify trendings per transport type reported:
```{r Trending per transport type (Apple)}
mobility_apple %>% 
  ggplot(aes(x = date, y = mobility)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Apple Mobility Index",
       subtitle = "Mexico City, January 2020 - July 2021",
       x = "Date",
       y = "Mobility") +
  facet_wrap(~transportation_type)
```

### Google mobility data

Read and filter Google's mobility data for Mexico City:
```{r Read Google mobility data}
mobility_google <-
  read_csv("Data/2020_MX_Region_Mobility_Report.csv.zip") %>% 
  filter(sub_region_1 == "Mexico City") %>% 
  pivot_longer(cols = (10:15),
               names_to = "mob_type",
               values_to = "mobility") %>% 
  glimpse()
```

Identify trendings per transport type reported:
```{r Trending per transport type (Google)}
mobility_google %>% 
  ggplot(aes(x = date, y = mobility, group = mob_type)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Google Mobility Index",
       subtitle = "Mexico City, February 2020 - December 2020",
       x = "Date",
       y = "Mobility") +
  facet_wrap(~mob_type)
```

Review mobility type categories for Google's mobility data:
```{r Mobility type categories}
mobility_google %>% 
  distinct(mob_type)
```

## Near repeat analysis (NRA)

### Street robbery

Set analysis parameters considering:

* Spatial interval (`sds`): 150 meters x 10 bands
* Temporal interval (`tds`): 3 days x 10 bands
* 99 iterations

```{r Street robbery NRA parameters}
spatial_interval <- 150
spatial_bands <- 10
temporal_interval <- 3
temporal_bands <- 10
iterations <- 99
```

Fix a randomization seed to ensure analysis reproducibility:
```{r Set seed}
set.seed(1234)
```

Filter street robbery data for the period before the lockdown and prepare it for NRA:
```{r Prepare street robbery data}
street_robberies <-
  hi_robberies_points %>% 
  filter(categoria_delito == "ROBO A TRANSEUNTE EN VÍA PÚBLICA CON Y SIN VIOLENCIA",
         between(fecha, date_start, lockdown_date)) %>% 
  st_transform(6369) %>% # Transform to projected CRS
  select(fecha) # Keep just the date variable

street_robberies <-
  street_robberies %>% 
  bind_cols(as_tibble(st_coordinates(street_robberies))) %>% # Add coordinates
  as_tibble() %>% # Convert from spatial to plain tibble
  clean_names() %>% # Clean variable names
  select(fecha, x, y) %>% 
  remove_missing() %>% # Remove incomplete rows
  glimpse()
```

Apply NRA model using the parameters defined below:
```{r NRA model for street robberies}
street_robberies_nra <- 
  NearRepeat(x = street_robberies$x,
             y = street_robberies$y,
             time = street_robberies$fecha,
             sds = seq(0, by = spatial_interval, length.out = spatial_bands),
             tds = seq(0, by = temporal_interval, length.out = temporal_bands),
             nrep = iterations)

street_robberies_nra
```

Visualize *p* values for each distance and time interval:
```{r Visualize street robbery NRA}
plot(street_robberies_nra)
```

### Vehicle theft

Set analysis parameters considering:

* Spatial interval (`sds`): 250 meters x 10 bands
* Temporal interval (`tds`): 7 days x 10 bands
* 99 iterations

```{r Vehicle theft NRA parameters}
spatial_interval <- 250
spatial_bands <- 10
temporal_interval <- 7
temporal_bands <- 10
iterations <- 99
```

Filter car theft data for the period before the lockdown and prepare it for NRA:
```{r Prepare vehicle theft data}
vehicle_theft <-
  hi_robberies_points %>% 
  filter(categoria_delito == "ROBO DE VEHÍCULO CON Y SIN VIOLENCIA",
         between(fecha, date_start, lockdown_date)) %>% 
  st_transform(6369) %>% 
  select(fecha) 

vehicle_theft <-
  vehicle_theft %>% 
  bind_cols(as_tibble(st_coordinates(vehicle_theft))) %>% 
  as_tibble() %>% 
  clean_names() %>% 
  select(fecha, x, y) %>% 
  remove_missing() %>% 
  glimpse()
```

Apply NRA model using the parameters defined below:
```{r NRA model for vehicle theft}
vehicle_theft_nra <- 
  NearRepeat(x = vehicle_theft$x,
             y = vehicle_theft$y,
             time = vehicle_theft$fecha,
             sds = seq(0, by = spatial_interval, length.out = spatial_bands),
             tds = seq(0, by = temporal_interval, length.out = temporal_bands),
             nrep = iterations)

vehicle_theft_nra
```

Visualize *p* values for each distance and time interval:
```{r Visualize vehicle theft NRA}
plot(vehicle_theft_nra)
```

Save analysis data:
```{r Save NRA results}
save(street_robberies_nra, vehicle_theft_nra, file = "Output/nra_150mx10_3dx10.Rdata")
```

## Spatio-temporal interactions

Define a function for selecting near points within the distance and time thresholds:
```{r Function for searching near points}
search_near_points <- function(point_id, points_set, distance_threshold, time_threshold) {
  
  point_origin <-
    points_set %>% 
    filter(id_point == point_id)
  
  points_near <-
    points_set %>% 
    filter(between(fecha, point_origin$fecha - time_threshold, point_origin$fecha + time_threshold)) %>% 
    filter(lengths(st_is_within_distance(x = ., y = point_origin, dist = distance_threshold)) > 0) %>% 
    pull(id_point)
  
  return(points_near)

}
```

Define a function for creating the spatio-temporal interaction lines (STIL) connecting points near on time and distance:
```{r Function for creating lines}
create_sti_line <- function(point_id, points_set, distance_threshold, time_threshold) {
  
  point_origin <- 
    points_set %>% 
    filter(id_point == point_id)
  
  points_id_near <- search_near_points(point_id, points_set, distance_threshold, time_threshold)
  
  for(i in points_id_near) {
    point_near <-
      points_set %>% 
      filter(id_point == i)
    
    new_line <- 
      matrix(c(as.numeric(st_coordinates(point_origin)),
               as.numeric(st_coordinates(point_near))),
             ncol = 2,
             byrow = TRUE) %>% 
      st_linestring() %>% 
      st_sfc(crs = 4326) %>%
      st_sf()
    
    if(!exists("sti_lines")){
      sti_lines <- new_line
    } else {
      sti_lines <- bind_rows(sti_lines, new_line)
    }
    
  }
  
  return(sti_lines)
  
}
```

Define space and time thresholds:
```{r Space and time thresholds}
distance_threshold <- set_units(150, m)
time_threshold <- period(12, "days")
```

Filter crime and period to analyze:
```{r Filter crime and period}
analyzed_crime <- "ROBO A TRANSEUNTE EN VÍA PÚBLICA CON Y SIN VIOLENCIA"
# analyzed_crime <- "ROBO DE VEHÍCULO CON Y SIN VIOLENCIA"
# period_start <- date_start
period_start <- lockdown_date - period(3, units = "week")
period_end <- lockdown_date

points_original <-
  hi_robberies_points %>%
  filter(between(fecha, period_start, period_end),
         categoria_delito == analyzed_crime) %>% 
  glimpse()
```

Process crime spatial points:
```{r Process points}
points_to_process <- points_original$id_point

if(exists("sti_lines_total")) rm(sti_lines_total)

while(length(points_to_process) > 0) {
  
  points_left <- first(points_to_process)
  points_accumulated <- points_left
  
  # Search for points near in time and distance thresholds:
  while(length(points_left) > 0) {
    
    points_found <- unlist(map(points_left, 
                               search_near_points,
                               points_original,
                               distance_threshold,
                               time_threshold))
    
    points_left <- points_found[!(points_found %in% points_accumulated)]
    
    points_accumulated <- 
      c(points_accumulated, points_found) %>% 
      unique() %>% 
      sort()
    
  }
  
  # Build spatio temporal interaction lines between the near points found:
  sti_points <-
    points_original %>% 
    filter(id_point %in% points_accumulated)
  
  if(nrow(sti_points) > 1) {
    
    sti_line <- 
      map_df(sti_points$id_point,
             create_sti_line,
             sti_points,
             distance_threshold,
             time_threshold) %>% 
      filter(as.numeric(st_length(geometry)) > 0 ) %>% # Remove lines connecting a point with itself
      distinct() %>% # Remove duplicated lines
      st_combine() %>% 
      st_sf() %>% 
      st_set_crs(4326) %>% 
      mutate(nodos = length(points_accumulated))
    
    if(exists("sti_lines_total")) {
      sti_lines_total <- bind_rows(sti_lines_total, sti_line)
    } else {
      sti_lines_total <- sti_line
    }
    
  }
  
  points_to_process <- points_to_process[!(points_to_process %in% points_accumulated)]
  
}
```

Categorize STILs:
```{r Categorize spatio-temporal lines}
classification <- classIntervals(sti_lines_total$nodos, n = 4, style = "fisher")
classification
```

Categorize lines by the number of connected nodes:
```{r Categorize lines}
sti_lines_total <-
  sti_lines_total %>%
  mutate(categoria = cut(nodos, 
                         breaks = classification$brks,
                         labels = c(1:(length(classification$brks) - 1)))) %>% 
  glimpse()
```

Visualize STILs in an interactive map:
```{r Map visualization of STIL}
tmap_mode("view")

sti_lines_total %>%
  filter(categoria %in% c("2", "3", "4")) %>% 
  tm_shape() +
  tm_basemap(alpha = 0.5) +
  tm_lines(col = "categoria", 
           palette = "YlOrRd",
           title.col = "Interaction category")
```

Save the STIL layer in a file:
```{r Save STIL layer}
st_write(sti_lines_total, 
         dsn = str_glue("Output/sti_lines-{date_start}-{date_end}_{file_timestamp}.gpkg",
                        date_start = make_clean_names(period_start),
                        date_end = make_clean_names(period_end),
                        file_timestamp = make_clean_names(now())),
         delete_dsn = T)
```
